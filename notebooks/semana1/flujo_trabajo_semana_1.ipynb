{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4.1312    ,   35.        ,    5.88235294, ...,    2.98529412,\n",
       "          33.93      , -118.02      ],\n",
       "       [   2.8631    ,   20.        ,    4.40120968, ...,    2.0141129 ,\n",
       "          32.79      , -117.09      ],\n",
       "       [   4.2026    ,   24.        ,    5.61754386, ...,    2.56491228,\n",
       "          34.59      , -120.14      ],\n",
       "       ...,\n",
       "       [   2.9344    ,   36.        ,    3.98671727, ...,    3.33206831,\n",
       "          34.03      , -118.38      ],\n",
       "       [   5.7192    ,   15.        ,    6.39534884, ...,    3.17889088,\n",
       "          37.58      , -121.96      ],\n",
       "       [   2.5755    ,   52.        ,    3.40257649, ...,    2.10869565,\n",
       "          37.77      , -122.42      ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = fetch_california_housing()\n",
    "x,y = data.data , data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "    x,y,\n",
    "    test_size=0.3,   # Porcentaje del dataset para el conjunto de prueba\n",
    "    random_state=42, # Controlar la aleatoriedad\n",
    "    shuffle=True,    # Mezclar los datos antes de dividir\n",
    "    stratify=None    # Estratificar por y si es Clasificacion\n",
    ")\n",
    "\n",
    "x.shape\n",
    "X_train.shape\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Valores Faltantes con SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "   A    B    C\n",
      "0  1  2.0  NaN\n",
      "1  3  NaN  6.0\n",
      "2  7  8.0  9.0\n",
      "nDatos imputados:\n",
      "     A    B    C\n",
      "0  1.0  2.0  7.5\n",
      "1  3.0  5.0  6.0\n",
      "2  7.0  8.0  9.0\n"
     ]
    }
   ],
   "source": [
    "#Manejo de Valores Faltantes con SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Datos con valores faltantes\n",
    "X = pd.DataFrame({\n",
    "    'A': [1, 3, 7],\n",
    "    'B': [2, None, 8],\n",
    "    'C': [None, 6, 9]\n",
    "})\n",
    "\n",
    "print(\"Datos originales:\")\n",
    "print(X)\n",
    "\n",
    "# Crear un imputador con la estrategia de la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Convertir el resultado a un DataFrame de pandas\n",
    "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "print(\"nDatos imputados:\")\n",
    "print(X_imputed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificación One-Hot con OneHotEncoder\n",
    "\n",
    "La codificación One-Hot convierte cada categoría en una nueva columna binaria y asigna un valor de 1 o 0 para indicar la presencia o ausencia de esa categoría. Esto permite que los algoritmos de aprendizaje automático procesen las variables categóricas de manera efectiva.\n",
    "\n",
    "Scikit-learn proporciona la clase OneHotEncoder para realizar la codificación One-Hot. Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Datos categóricos\n",
    "X = [['rojo'], ['verde'], ['azul'], ['verde'], ['rojo']]\n",
    "\n",
    "# Crear un codificador One-Hot\n",
    "# El orden de las columnas es por orden alfabetico ['azul', 'rojo', 'verde']\n",
    "#encoder = OneHotEncoder()\n",
    "# Si queremos definir otro orden para las columnas\n",
    "encoder = OneHotEncoder(categories=[['rojo', 'verde', 'azul']])\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "print(X_encoded.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificación de Etiquetas con LabelEncoder   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Datos categóricos\n",
    "y = ['rojo', 'verde', 'azul', 'verde', 'rojo']\n",
    "\n",
    "# Crear un codificador de etiquetas por orden alfabetico\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Integración en un Flujo de Trabajo de Aprendizaje Automático*\n",
    "\n",
    "Ahora que hemos aprendido sobre SimpleImputer, OneHotEncoder y LabelEncoder, veamos cómo integrarlos en un flujo de trabajo completo de aprendizaje automático.\n",
    "\n",
    "En este ejemplo:\n",
    "\n",
    "1. Cargamos el conjunto de datos «tic-tac-toe» utilizando fetch_openml() de Scikit-learn.\n",
    "2. Dividimos los datos en conjuntos de entrenamiento y prueba utilizando train_test_split().\n",
    "3. Creamos instancias de SimpleImputer y OneHotEncoder para manejar valores faltantes y codificar variables categóricas, respectivamente.\n",
    "4. Preprocesamos los datos de entrenamiento y prueba utilizando los transformadores.\n",
    "5. Codificamos las etiquetas de destino utilizando LabelEncoder.\n",
    "6. Creamos y entrenamos un clasificador de árboles de decisión.\n",
    "7. Hacemos predicciones en el conjunto de prueba y calculamos la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.9739583333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "X, y = fetch_openml('tic-tac-toe', version=1, return_X_y=True)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear un imputador para manejar valores faltantes\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Crear un codificador One-Hot para variables categóricas\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Preprocesar los datos de entrenamiento\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_train_encoded = encoder.fit_transform(X_train_imputed)\n",
    "\n",
    "# Preprocesar los datos de prueba\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "X_test_encoded = encoder.transform(X_test_imputed)\n",
    "\n",
    "# Codificar las etiquetas de destino\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Crear y entrenar un clasificador de árboles de decisión\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = classifier.predict(X_test_encoded)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "X, y = fetch_openml('tic-tac-toe', version=1, return_X_y=True)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  top-left-square top-middle-square  ... bottom-middle-square bottom-right-square\n",
      "0               x                 x  ...                    o                   o\n",
      "1               x                 x  ...                    x                   o\n",
      "2               x                 x  ...                    o                   x\n",
      "3               x                 x  ...                    b                   b\n",
      "4               x                 x  ...                    o                   b\n",
      "\n",
      "[5 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X.head())  # Ver las primeras filas de características\n",
    "#print(y[:5])     # Ver las primeras etiquetas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "data_bunch = fetch_openml('tic-tac-toe', version=1, as_frame=True)\n",
    "print(type(data_bunch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_ds02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
